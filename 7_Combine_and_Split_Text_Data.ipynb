{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured and text data\n",
    " \n",
    "- Already separate datasets for outcomes split by training, test \n",
    "- Combine structured data with text features and list of strings\n",
    "- Aim: create final dataset to feed into model\n",
    "- NB NOT including tfidf and topic modelling - these are completed as transformer steps in the gridsearchcv pipeline in the analysis notebooks - as otherwise there would be data leakage between cross validation folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user-written functions\n",
    "\n",
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')\n",
    "\n",
    "import analysis_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in text features (vulnerabilities, concreteness, emotions NOT tfidf or topics)\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\") # insert [username]\n",
    "\n",
    "filename = open(\"Created/text_rq1_vulnerabilities.pkl\", \"rb\")\n",
    "df_text_features_vulnerabilities_rq1 = pickle.load(filename)\n",
    "print(df_text_features_vulnerabilities_rq1.shape)\n",
    "print(df_text_features_vulnerabilities_rq1.index)\n",
    "\n",
    "\n",
    "filename = open(\"Created/text_rq2_vulnerabilities.pkl\", \"rb\")\n",
    "df_text_features_vulnerabilities_rq2 = pickle.load(filename)\n",
    "print(df_text_features_vulnerabilities_rq2.shape)\n",
    "print(df_text_features_vulnerabilities_rq2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set working directory\n",
    "\n",
    "# Import structured data (with all the final data cleaning but before it's split)\n",
    "# These datasets created in 5a_Combine_Data\n",
    "filename = open(\"../Updated Structured Data/Created/df_outcome1_before_splitting.pkl\", \"rb\")\n",
    "df_outcome1_before_splitting = pickle.load(filename)\n",
    "print(df_outcome1_before_splitting.shape)\n",
    "\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_outcome2_before_splitting.pkl\", \"rb\")\n",
    "df_outcome2_before_splitting = pickle.load(filename)\n",
    "print(df_outcome2_before_splitting.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select the same rows as the cleaned structured data\n",
    "# By merging on the key cols\n",
    "import pandas as pd\n",
    "# Format \n",
    "df_text_features_vulnerabilities_rq1['ReferralDatetime'] = pd.to_datetime(df_text_features_vulnerabilities_rq1['ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq2['ReferralDatetime'] = pd.to_datetime(df_text_features_vulnerabilities_rq2['ReferralDatetime'])\n",
    "\n",
    "\n",
    "# rq1 \n",
    "df_text_features_vulnerabilities_rq1 = pd.merge(df_outcome1_before_splitting[['PSID', 'ReferralDatetime']], df_text_features_vulnerabilities_rq1, on = ['PSID', 'ReferralDatetime'], how = 'left')\n",
    "df_text_features_vulnerabilities_rq1.drop_duplicates(subset = ['PSID', 'ReferralDatetime'], inplace = True)\n",
    "df_text_features_vulnerabilities_rq1.sort_values(by = 'ReferralDatetime', inplace = True)\n",
    "print(df_text_features_vulnerabilities_rq1.shape)\n",
    "\n",
    "\n",
    "# rq2\n",
    "df_text_features_vulnerabilities_rq2 = pd.merge(df_outcome2_before_splitting[['PSID', 'ReferralDatetime']], df_text_features_vulnerabilities_rq2, on = ['PSID', 'ReferralDatetime'], how = 'left')\n",
    "df_text_features_vulnerabilities_rq2.drop_duplicates(subset = ['PSID', 'ReferralDatetime'], inplace = True)\n",
    "df_text_features_vulnerabilities_rq2.sort_values(by = 'ReferralDatetime', inplace = True)\n",
    "print(df_text_features_vulnerabilities_rq2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = open(\"../Data for Model/X_train_rq1_ts_str.pkl\", \"rb\")\n",
    "X_train_rq1_ts = pickle.load(filename)\n",
    "print(X_train_rq1_ts.shape)\n",
    "print(X_train_rq1_ts.index)\n",
    "\n",
    "filename = open(\"../Data for Model/X_test_rq1_ts_str.pkl\", \"rb\")\n",
    "X_test_rq1_ts = pickle.load(filename)\n",
    "print(X_test_rq1_ts.shape)\n",
    "print(X_test_rq1_ts.index)\n",
    "\n",
    "filename = open(\"../Data for Model/X_train_rq1_ss_str.pkl\", \"rb\")\n",
    "X_train_rq1_ss = pickle.load(filename)\n",
    "print(X_train_rq1_ss.shape)\n",
    "print(X_train_rq1_ss.index)\n",
    "\n",
    "filename = open(\"../Data for Model/X_test_rq1_ss_str.pkl\", \"rb\")\n",
    "X_test_rq1_ss = pickle.load(filename)\n",
    "print(X_test_rq1_ss.shape)\n",
    "print(X_test_rq1_ss.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "filename = open(\"../Data for Model/X_train_rq2_ts_str.pkl\", \"rb\")\n",
    "X_train_rq2_ts = pickle.load(filename)\n",
    "print(X_train_rq2_ts.shape)\n",
    "print(X_train_rq2_ts.index)\n",
    "\n",
    "filename = open(\"../Data for Model/X_test_rq2_ts_str.pkl\", \"rb\")\n",
    "X_test_rq2_ts = pickle.load(filename)\n",
    "print(X_test_rq2_ts.shape)\n",
    "print(X_test_rq2_ts.index)\n",
    "\n",
    "filename = open(\"../Data for Model/X_train_rq2_ss_str.pkl\", \"rb\")\n",
    "X_train_rq2_ss = pickle.load(filename)\n",
    "print(X_train_rq2_ss.shape)\n",
    "print(X_train_rq2_ss.index)\n",
    "\n",
    "filename = open(\"../Data for Model/X_test_rq2_ss_str.pkl\", \"rb\")\n",
    "X_test_rq2_ss = pickle.load(filename)\n",
    "print(X_test_rq2_ss.shape)\n",
    "print(X_test_rq2_ss.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_text_features_vulnerabilities with train, test,  \n",
    "# Merge on left with the train etc data on the left so just those rows picked up\n",
    "\n",
    "df_text_features_vulnerabilities_rq1_ts_train = pd.merge(X_train_rq1_ts, df_text_features_vulnerabilities_rq1, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq1_ts_train.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq1_ts_train.shape)\n",
    "print(X_train_rq1_ts.shape)\n",
    "print(df_text_features_vulnerabilities_rq1_ts_train.index)\n",
    "\n",
    "df_text_features_vulnerabilities_rq1_ts_test = pd.merge(X_test_rq1_ts, df_text_features_vulnerabilities_rq1, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq1_ts_test.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq1_ts_test.shape)\n",
    "print(X_test_rq1_ts.shape)\n",
    "print(df_text_features_vulnerabilities_rq1_ts_test.index)\n",
    "\n",
    "df_text_features_vulnerabilities_rq1_ss_train = pd.merge(X_train_rq1_ss, df_text_features_vulnerabilities_rq1, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq1_ss_train.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq1_ss_train.shape)\n",
    "print(X_train_rq1_ss.shape)\n",
    "print(df_text_features_vulnerabilities_rq1_ss_train.index)\n",
    "\n",
    "df_text_features_vulnerabilities_rq1_ss_test = pd.merge(X_test_rq1_ss, df_text_features_vulnerabilities_rq1, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq1_ss_test.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq1_ss_test.shape)\n",
    "print(X_test_rq1_ss.shape)\n",
    "print(df_text_features_vulnerabilities_rq1_ss_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training, test  data\n",
    "\n",
    "# RQ1\n",
    "with open(\"../Data for Model/df_text__vulnerabilities_rq1_ts_train.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq1_ts_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/df_text_features_vulnerabilities_rq1_ts_test.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq1_ts_test, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "with open(\"../Data for Model/df_text_features_vulnerabilities_rq1_ss_train.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq1_ss_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/df_text_features_vulnerabilities_rq1_ss_test.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq1_ss_test, handle, protocol = pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_text_features_vulnerabilities with train, test,  \n",
    "# Merge on left with the train etc data on the left so just those rows picked up\n",
    "\n",
    "df_text_features_vulnerabilities_rq2_ts_train = pd.merge(X_train_rq2_ts, df_text_features_vulnerabilities_rq2, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq2_ts_train.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq2_ts_train.shape)\n",
    "print(X_train_rq2_ts.shape)\n",
    "print(df_text_features_vulnerabilities_rq2_ts_train.index)\n",
    "\n",
    "df_text_features_vulnerabilities_rq2_ts_test = pd.merge(X_test_rq2_ts, df_text_features_vulnerabilities_rq2, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq2_ts_test.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq2_ts_test.shape)\n",
    "print(X_test_rq2_ts.shape)\n",
    "print(df_text_features_vulnerabilities_rq2_ts_test.index)\n",
    "\n",
    "df_text_features_vulnerabilities_rq2_ss_train = pd.merge(X_train_rq2_ss, df_text_features_vulnerabilities_rq2, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq2_ss_train.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq2_ss_train.shape)\n",
    "print(X_train_rq2_ss.shape)\n",
    "print(df_text_features_vulnerabilities_rq2_ss_train.index)\n",
    "\n",
    "df_text_features_vulnerabilities_rq2_ss_test = pd.merge(X_test_rq2_ss, df_text_features_vulnerabilities_rq2, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "df_text_features_vulnerabilities_rq2_ss_test.reset_index(inplace = True, drop = True)\n",
    "print(df_text_features_vulnerabilities_rq2_ss_test.shape)\n",
    "print(X_test_rq2_ss.shape)\n",
    "print(df_text_features_vulnerabilities_rq2_ss_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save training, test  data\n",
    "\n",
    "# rq2\n",
    "with open(\"../Data for Model/df_text_features_vulnerabilities_rq2_ts_train.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq2_ts_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/df_text_features_vulnerabilities_rq2_ts_test.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq2_ts_test, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/df_text_features_vulnerabilities_rq2_ss_train.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq2_ss_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/df_text_features_vulnerabilities_rq2_ss_test.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_text_features_vulnerabilities_rq2_ss_test, handle, protocol = pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\") # insert [username]\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_train_rq1_ts_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq1_ts_train = pickle.load(filename)\n",
    "# Referral_Start_Date dropped to avoid duplicate (don't match on it with so many missing)\n",
    "#df_tfidf_topics_rq1_ts_train.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq1_ts_train.shape)\n",
    "print(df_tfidf_topics_rq1_ts_train.index)\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_test_rq1_ts_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq1_ts_test = pickle.load(filename)\n",
    "#df_tfidf_topics_rq1_ts_test.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq1_ts_test.shape)\n",
    "print(df_tfidf_topics_rq1_ts_test.index)\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_train_rq1_ss_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq1_ss_train = pickle.load(filename)\n",
    "#df_tfidf_topics_rq1_ss_train.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq1_ss_train.shape)\n",
    "print(df_tfidf_topics_rq1_ss_train.index)\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_test_rq1_ss_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq1_ss_test = pickle.load(filename)\n",
    "#df_tfidf_topics_rq1_ss_test.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq1_ss_test.shape)\n",
    "print(df_tfidf_topics_rq1_ss_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\") # insert [username]\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_train_rq2_ts_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq2_ts_train = pickle.load(filename)\n",
    "# Referral_Start_Date dropped to avoid duplicate (don't match on it with so many missing)\n",
    "#df_tfidf_topics_rq2_ts_train.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq2_ts_train.shape)\n",
    "print(df_tfidf_topics_rq2_ts_train.index)\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_test_rq2_ts_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq2_ts_test = pickle.load(filename)\n",
    "#df_tfidf_topics_rq2_ts_test.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq2_ts_test.shape)\n",
    "print(df_tfidf_topics_rq2_ts_test.index)\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_train_rq2_ss_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq2_ss_train = pickle.load(filename)\n",
    "#df_tfidf_topics_rq2_ss_train.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq2_ss_train.shape)\n",
    "print(df_tfidf_topics_rq2_ss_train.index)\n",
    "\n",
    "filename = open(\"../Updated Structured Data/Created/df_tfidf_topics_test_rq2_ss_all.pkl\", \"rb\")\n",
    "df_tfidf_topics_rq2_ss_test = pickle.load(filename)\n",
    "#df_tfidf_topics_rq2_ss_test.drop(columns = 'ReferralDatetime', inplace = True)\n",
    "print(df_tfidf_topics_rq2_ss_test.shape)\n",
    "print(df_tfidf_topics_rq2_ss_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge structured and text feature data with list of strings data\n",
    "print(df_text_features_vulnerabilities_rq1_ts_train.shape)\n",
    "print(df_tfidf_topics_rq1_ts_train.shape)\n",
    "df_str_text_rq1_ts_train = pd.merge(df_text_features_vulnerabilities_rq1_ts_train, df_tfidf_topics_rq1_ts_train, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq1_ts_train.shape)\n",
    "\n",
    "print(df_text_features_vulnerabilities_rq1_ts_test.shape)\n",
    "print(df_tfidf_topics_rq1_ts_test.shape)\n",
    "df_str_text_rq1_ts_test = pd.merge(df_text_features_vulnerabilities_rq1_ts_test, df_tfidf_topics_rq1_ts_test, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq1_ts_test.shape) \n",
    "\n",
    "print(df_text_features_vulnerabilities_rq1_ss_train.shape)\n",
    "print(df_tfidf_topics_rq1_ss_train.shape)\n",
    "df_str_text_rq1_ss_train = pd.merge(df_text_features_vulnerabilities_rq1_ss_train, df_tfidf_topics_rq1_ss_train, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq1_ss_train.shape)\n",
    "\n",
    "\n",
    "print(df_text_features_vulnerabilities_rq1_ss_test.shape)\n",
    "print(df_tfidf_topics_rq1_ss_test.shape)\n",
    "df_str_text_rq1_ss_test = pd.merge(df_text_features_vulnerabilities_rq1_ss_test, df_tfidf_topics_rq1_ss_test, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq1_ss_test.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge structured and text feature data with list of strings data\n",
    "\n",
    "print(df_text_features_vulnerabilities_rq2_ts_train.shape)\n",
    "print(df_tfidf_topics_rq2_ts_train.shape)\n",
    "df_str_text_rq2_ts_train = pd.merge(df_text_features_vulnerabilities_rq2_ts_train, df_tfidf_topics_rq2_ts_train, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq2_ts_train.shape)\n",
    "\n",
    "print(df_text_features_vulnerabilities_rq2_ts_test.shape)\n",
    "print(df_tfidf_topics_rq2_ts_test.shape)\n",
    "df_str_text_rq2_ts_test = pd.merge(df_text_features_vulnerabilities_rq2_ts_test, df_tfidf_topics_rq2_ts_test, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq2_ts_test.shape)    \n",
    "\n",
    "print(df_text_features_vulnerabilities_rq2_ss_train.shape)\n",
    "print(df_tfidf_topics_rq2_ss_train.shape)\n",
    "df_str_text_rq2_ss_train = pd.merge(df_text_features_vulnerabilities_rq2_ss_train, df_tfidf_topics_rq2_ss_train, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq2_ss_train.shape)\n",
    "\n",
    "print(df_text_features_vulnerabilities_rq2_ss_test.shape)\n",
    "print(df_tfidf_topics_rq2_ss_test.shape)\n",
    "df_str_text_rq2_ss_test = pd.merge(df_text_features_vulnerabilities_rq2_ss_test, df_tfidf_topics_rq2_ss_test, how = 'left', on = ['PSID', 'ReferralDatetime'])\n",
    "print(df_str_text_rq2_ss_test.shape)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting indices in preparation for splits (splitters expect range index)\n",
    "print(df_str_text_rq1_ts_train.index)\n",
    "df_str_text_rq1_ts_train.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq1_ts_train.index)\n",
    "print(df_str_text_rq1_ts_test.index)\n",
    "df_str_text_rq1_ts_test.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq1_ts_test.index)\n",
    "\n",
    "print(df_str_text_rq1_ss_train.index)\n",
    "df_str_text_rq1_ss_train.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq1_ss_train.index)\n",
    "print(df_str_text_rq1_ss_test.index)\n",
    "df_str_text_rq1_ss_test.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq1_ss_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resetting indices in preparation for splits (splitters expect range index)\n",
    "print(df_str_text_rq2_ts_train.index)\n",
    "df_str_text_rq2_ts_train.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq2_ts_train.index)\n",
    "print(df_str_text_rq2_ts_test.index)\n",
    "df_str_text_rq2_ts_test.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq2_ts_test.index)\n",
    "\n",
    "print(df_str_text_rq2_ss_train.index)\n",
    "df_str_text_rq2_ss_train.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq2_ss_train.index)\n",
    "print(df_str_text_rq2_ss_test.index)\n",
    "df_str_text_rq2_ss_test.reset_index(inplace = True, drop = True)\n",
    "print(df_str_text_rq2_ss_test.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training, test  data\n",
    "\n",
    "# RQ1\n",
    "\n",
    "with open(\"../Data for Model/X_train_rq1_ts_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq1_ts_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/X_test_rq1_ts_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq1_ts_test, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/X_train_rq1_ss_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq1_ss_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/X_test_rq1_ss_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq1_ss_test, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save training, test  data\n",
    "\n",
    "# RQ2\n",
    "with open(\"../Data for Model/X_train_rq2_ts_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq2_ts_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/X_test_rq2_ts_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq2_ts_test, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "with open(\"../Data for Model/X_train_rq2_ss_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq2_ss_train, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"../Data for Model/X_test_rq2_ss_all.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df_str_text_rq2_ss_test, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change data to csvs for inspection\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "filename_list = [file for file in glob.glob(\"../Data for Model/*.pkl\")]\n",
    "\n",
    "file_dict = {}\n",
    "for file in filename_list:\n",
    "    try:\n",
    "        filename = open(file, \"rb\")\n",
    "        f = pickle.load(filename)\n",
    "        file_n = re.sub('.pkl', '', file)\n",
    "        print(file_n)\n",
    "        f.to_csv('{}.csv'.format(file_n))\n",
    "    except(EOFError):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks to make sure indices are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\") # insert [username]\n",
    "\n",
    "filename_list = [file for file in glob.glob('../Data for Model/*test_rq2_ts_*.csv')]\n",
    "\n",
    "for file in filename_list:\n",
    "    df = pd.read_csv(file, index_col = 0)\n",
    "    print(file)\n",
    "    print(df.shape)\n",
    "    print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for train / test and rq1 / rq2 and ts / ss\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\") # insert [username]\n",
    "\n",
    "sib = pd.read_csv('../Data for Model\\siblings_train_rq1_ts_str.csv', index_col = 0, header = None)\n",
    "X_test_all = pd.read_csv('../Data for Model\\X_train_rq1_ts_all.csv', index_col = 0)\n",
    "X_test_str = pd.read_csv('../Data for Model\\X_train_rq1_ts_str.csv', index_col = 0)\n",
    "y_test = pd.read_csv('../Data for Model\\y_train_rq1_ts_str.csv', index_col = 0, header = None)\n",
    "\n",
    "print(sib.shape)\n",
    "print(X_test_all.shape)\n",
    "print(X_test_str.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(sib.index)\n",
    "print(X_test_all.index)\n",
    "print(X_test_str.index)\n",
    "print(y_test.index)\n",
    "\n",
    "assert (X_test_all['PSID'].reset_index() == X_test_str['PSID'].reset_index()).all()['PSID']\n",
    "assert (X_test_all['ReferralDatetime'].reset_index() == X_test_str['ReferralDatetime'].reset_index()).all()['ReferralDatetime']\n",
    "\n",
    "X_test_all.set_index(X_test_str.index, inplace = True)\n",
    "print(X_test_all.index)\n",
    "X_test_all.to_csv('../Data for Model\\X_train_rq1_ts_str_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure indices match between siblings and y and X\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\") # insert [username]\n",
    "\n",
    "sib = pd.read_csv('../Data for Model\\siblings_train_rq2_ts_str.csv', index_col = 0, header = None)\n",
    "X_train_all = pd.read_csv('../Data for Model\\X_train_rq2_ts_all.csv', index_col = 0)\n",
    "X_train_str = pd.read_csv('../Data for Model\\X_train_rq2_ts_str.csv', index_col = 0)\n",
    "y_train = pd.read_csv('../Data for Model\\y_train_rq2_ts_str.csv', index_col = 0, header = None)\n",
    "print(sib.shape)\n",
    "print(X_train_all.shape)\n",
    "print(X_train_str.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# y alignment\n",
    "# Take the index from the structured data\n",
    "# Merge on PSID and ReferralDatetime\n",
    "# Then reset the index from the structured data as for the all data\n",
    "X_train_str['index'] = X_train_str.index\n",
    "X_train_all_new = pd.merge(X_train_str[['PSID', 'ReferralDatetime', 'index']], X_train_all, on = ['PSID', 'ReferralDatetime'], how = 'left')\n",
    "print(X_train_all_new.shape)\n",
    "X_train_all_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(X_train_all_new.shape)\n",
    "print(X_train_all_new.index)\n",
    "print(X_train_all.index)\n",
    "print(X_train_str.index)\n",
    "X_train_all_new.set_index('index', drop = True, inplace = True)\n",
    "print(X_train_all_new.index)\n",
    "\n",
    "X_train_all_new.to_csv('../Data for Model\\X_train_rq2_ts_str_new.csv')\n",
    "\n",
    "### Siblings alignment\n",
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Structured Data\\\\Created\") # insert [username]\n",
    "\n",
    "filename = open(\"df_outcome1_before_splitting.pkl\", \"rb\")\n",
    "df_outcome1_before_splitting = pickle.load(filename)\n",
    "print(df_outcome1_before_splitting.shape)\n",
    "\n",
    "filename = open(\"df_outcome2_before_splitting.pkl\", \"rb\")\n",
    "df_outcome2_before_splitting = pickle.load(filename)\n",
    "print(df_outcome2_before_splitting.shape)\n",
    "\n",
    "sib_new = pd.merge(X_train_str[['PSID', 'index']], df_outcome2_before_splitting[['PSID', 'PseudoID']], on = ['PSID'], how = 'left')\n",
    "\n",
    "sib_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(sib_new.shape)\n",
    "print(sib_new.index)\n",
    "print(sib.index)\n",
    "sib_new.set_index('index', drop = True, inplace = True)\n",
    "print(sib_new.index)\n",
    "sib_new.drop(columns = ['PSID'], inplace = True)\n",
    "\n",
    "# Checking no siblings overlap\n",
    "sib_test = pd.read_csv('../../Data for Model\\siblings_test_rq2_ts_str.csv', index_col = 0, header = None)\n",
    "assert len(set(sib_new['PseudoID']).intersection(set(sib_test[1]))) <= 1\n",
    "\n",
    "sib_new.to_csv('../../Data for Model\\siblings_train_rq2_ts_str_new.csv')\n",
    "\n",
    "print(X_train_str.index)\n",
    "print(X_train_all_new.index)\n",
    "print(sib_new.index)\n",
    "assert (X_train_str.index == X_train_all_new.index).all()\n",
    "assert (X_train_str.index == sib_new.index).all()\n",
    "assert (X_train_all_new.index == sib_new.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure indices match between siblings and y and X\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\") # insert [username]\n",
    "\n",
    "sib = pd.read_csv('../Data for Model\\siblings_test_rq2_ts_str.csv', index_col = 0, header = None)\n",
    "X_test_all = pd.read_csv('../Data for Model\\X_test_rq2_ts_all.csv', index_col = 0)\n",
    "X_test_str = pd.read_csv('../Data for Model\\X_test_rq2_ts_str.csv', index_col = 0)\n",
    "y_test = pd.read_csv('../Data for Model\\y_test_rq2_ts_str.csv', index_col = 0, header = None)\n",
    "print(sib.shape)\n",
    "print(X_test_all.shape)\n",
    "print(X_test_str.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "print(sib.index)\n",
    "print(X_test_all.index)\n",
    "print(X_test_str.index)\n",
    "print(y_test.index)\n",
    "\n",
    "# y alignment\n",
    "# Take the index from the structured data\n",
    "# Merge on PSID and ReferralDatetime\n",
    "# Then reset the index from the structured data as for the all data\n",
    "X_test_str['index'] = X_test_str.index\n",
    "X_test_all_new = pd.merge(X_test_str[['PSID', 'ReferralDatetime', 'index']], X_test_all, on = ['PSID', 'ReferralDatetime'], how = 'left')\n",
    "print(X_test_all_new.shape)\n",
    "X_test_all_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(X_test_all_new.shape)\n",
    "print(X_test_all_new.index)\n",
    "print(X_test_all.index)\n",
    "print(X_test_str.index)\n",
    "X_test_all_new.set_index('index', drop = True, inplace = True)\n",
    "print(X_test_all_new.index)\n",
    "\n",
    "X_test_all_new.to_csv('../Data for Model\\X_test_rq2_ts_str_new.csv')\n",
    "\n",
    "### Siblings alignment\n",
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Structured Data\\\\Created\") # insert [username]\n",
    "\n",
    "filename = open(\"df_outcome1_before_splitting.pkl\", \"rb\")\n",
    "df_outcome1_before_splitting = pickle.load(filename)\n",
    "print(df_outcome1_before_splitting.shape)\n",
    "\n",
    "filename = open(\"df_outcome2_before_splitting.pkl\", \"rb\")\n",
    "df_outcome2_before_splitting = pickle.load(filename)\n",
    "print(df_outcome2_before_splitting.shape)\n",
    "\n",
    "sib_new = pd.merge(X_test_str[['PSID', 'index']], df_outcome2_before_splitting[['PSID', 'PseudoID']], on = ['PSID'], how = 'left')\n",
    "\n",
    "sib_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(sib_new.shape)\n",
    "print(sib_new.index)\n",
    "print(sib.index)\n",
    "sib_new.set_index('index', drop = True, inplace = True)\n",
    "print(sib_new.index)\n",
    "sib_new.drop(columns = ['PSID'], inplace = True)\n",
    "\n",
    "# Checking no siblings overlap\n",
    "sib_train = pd.read_csv('../../Data for Model\\siblings_train_rq2_ts_str.csv', index_col = 0, header = None)\n",
    "assert len(set(sib_new['PseudoID']).intersection(set(sib_train[1]))) <= 1\n",
    "\n",
    "sib_new.to_csv('../../Data for Model\\siblings_test_rq2_ts_str_new.csv')\n",
    "\n",
    "print(X_test_str.index)\n",
    "print(X_test_all_new.index)\n",
    "print(sib_new.index)\n",
    "assert (X_test_str.index == X_test_all_new.index).all()\n",
    "assert (X_test_str.index == sib_new.index).all()\n",
    "assert (X_test_all_new.index == sib_new.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure indices match between siblings and y and X\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\")\n",
    "\n",
    "sib = pd.read_csv('../Data for Model\\siblings_train_rq2_ss_str.csv', index_col = 0, header = None)\n",
    "X_train_all = pd.read_csv('../Data for Model\\X_train_rq2_ss_all.csv', index_col = 0)\n",
    "X_train_str = pd.read_csv('../Data for Model\\X_train_rq2_ss_str.csv', index_col = 0)\n",
    "y_train = pd.read_csv('../Data for Model\\y_train_rq2_ss_str.csv', index_col = 0, header = None)\n",
    "\n",
    "print(sib.shape)\n",
    "print(X_train_all.shape)\n",
    "print(X_train_str.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# y alignment\n",
    "# Take the index from the structured data\n",
    "# Merge on PSID and ReferralDatetime\n",
    "# Then reset the index from the structured data as for the all data\n",
    "X_train_str['index'] = X_train_str.index\n",
    "X_train_all_new = pd.merge(X_train_str[['PSID', 'ReferralDatetime', 'index']], X_train_all, on = ['PSID', 'ReferralDatetime'], how = 'left')\n",
    "print(X_train_all_new.shape)\n",
    "X_train_all_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(X_train_all_new.shape)\n",
    "print(X_train_all_new.index)\n",
    "print(X_train_all.index)\n",
    "print(X_train_str.index)\n",
    "X_train_all_new.set_index('index', drop = True, inplace = True)\n",
    "print(X_train_all_new.index)\n",
    "\n",
    "X_train_all_new.to_csv('../Data for Model\\X_train_rq2_ss_str_new.csv')\n",
    "\n",
    "### Siblings alignment\n",
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Structured Data\\\\Created\")\n",
    "\n",
    "filename = open(\"df_outcome1_before_splitting.pkl\", \"rb\")\n",
    "df_outcome1_before_splitting = pickle.load(filename)\n",
    "print(df_outcome1_before_splitting.shape)\n",
    "\n",
    "filename = open(\"df_outcome2_before_splitting.pkl\", \"rb\")\n",
    "df_outcome2_before_splitting = pickle.load(filename)\n",
    "print(df_outcome2_before_splitting.shape)\n",
    "\n",
    "sib_new = pd.merge(X_train_str[['PSID', 'index']], df_outcome2_before_splitting[['PSID', 'PseudoID']], on = ['PSID'], how = 'left')\n",
    "\n",
    "sib_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(sib_new.shape)\n",
    "print(sib_new.index)\n",
    "print(sib.index)\n",
    "print(X_train_str.index)\n",
    "sib_new.set_index('index', drop = True, inplace = True)\n",
    "print(sib_new.index)\n",
    "sib_new.drop(columns = ['PSID'], inplace = True)\n",
    "\n",
    "# Checking no siblings overlap\n",
    "sib_test = pd.read_csv('../../Data for Model\\siblings_test_rq2_ss_str.csv', index_col = 0, header = None)\n",
    "assert len(set(sib_new['PseudoID']).intersection(set(sib_test[1]))) <= 1\n",
    "\n",
    "sib_new.to_csv('../../Data for Model\\siblings_train_rq2_ss_str_new.csv')\n",
    "\n",
    "print(X_train_str.index)\n",
    "print(X_train_all_new.index)\n",
    "print(sib_new.index)\n",
    "assert (X_train_str.index == X_train_all_new.index).all()\n",
    "assert (X_train_str.index == sib_new.index).all()\n",
    "assert (X_train_all_new.index == sib_new.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure indices match between siblings and y and X\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Text Data\")\n",
    "\n",
    "sib = pd.read_csv('../Data for Model\\siblings_test_rq2_ss_str.csv', index_col = 0, header = None)\n",
    "X_test_all = pd.read_csv('../Data for Model\\X_test_rq2_ss_all.csv', index_col = 0)\n",
    "X_test_str = pd.read_csv('../Data for Model\\X_test_rq2_ss_str.csv', index_col = 0)\n",
    "y_test = pd.read_csv('../Data for Model\\y_test_rq2_ss_str.csv', index_col = 0, header = None)\n",
    "\n",
    "print(sib.shape)\n",
    "print(X_test_all.shape)\n",
    "print(X_test_str.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(sib.index)\n",
    "print(X_test_all.index)\n",
    "print(X_test_str.index)\n",
    "print(y_test.index)\n",
    "\n",
    "# y alignment\n",
    "# Take the index from the structured data\n",
    "# Merge on PSID and ReferralDatetime\n",
    "# Then reset the index from the structured data as for the all data\n",
    "X_test_str['index'] = X_test_str.index\n",
    "X_test_all_new = pd.merge(X_test_str[['PSID', 'ReferralDatetime', 'index']], X_test_all, on = ['PSID', 'ReferralDatetime'], how = 'left')\n",
    "print(X_test_all_new.shape)\n",
    "X_test_all_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(X_test_all_new.shape)\n",
    "print(X_test_all_new.index)\n",
    "print(X_test_all.index)\n",
    "print(X_test_str.index)\n",
    "X_test_all_new.set_index('index', drop = True, inplace = True)\n",
    "print(X_test_all_new.index)\n",
    "\n",
    "X_test_all_new.to_csv('../Data for Model\\X_test_rq2_ss_str_new.csv')\n",
    "\n",
    "### Siblings alignment\n",
    "# Set working directory\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\Updated Structured Data\\\\Created\")\n",
    "\n",
    "filename = open(\"df_outcome1_before_splitting.pkl\", \"rb\")\n",
    "df_outcome1_before_splitting = pickle.load(filename)\n",
    "print(df_outcome1_before_splitting.shape)\n",
    "\n",
    "filename = open(\"df_outcome2_before_splitting.pkl\", \"rb\")\n",
    "df_outcome2_before_splitting = pickle.load(filename)\n",
    "print(df_outcome2_before_splitting.shape)\n",
    "\n",
    "sib_new = pd.merge(X_test_str[['PSID', 'index']], df_outcome2_before_splitting[['PSID', 'PseudoID']], on = ['PSID'], how = 'left')\n",
    "\n",
    "sib_new.drop_duplicates(subset = ['index'], keep = 'first', inplace = True)\n",
    "print(sib_new.shape)\n",
    "print(sib_new.index)\n",
    "print(sib.index)\n",
    "print(X_test_str.index)\n",
    "sib_new.set_index('index', drop = True, inplace = True)\n",
    "print(sib_new.index)\n",
    "sib_new.drop(columns = ['PSID'], inplace = True)\n",
    "\n",
    "# Checking no siblings overlap\n",
    "sib_train = pd.read_csv('../../Data for Model\\siblings_train_rq2_ss_str.csv', index_col = 0, header = None)\n",
    "assert len(set(sib_new['PseudoID']).intersection(set(sib_train[1]))) <= 1\n",
    "\n",
    "sib_new.to_csv('../../Data for Model\\siblings_test_rq2_ss_str_new.csv')\n",
    "\n",
    "print(X_test_str.index)\n",
    "print(X_test_all_new.index)\n",
    "print(sib_new.index)\n",
    "assert (X_test_str.index == X_test_all_new.index).all()\n",
    "assert (X_test_str.index == sib_new.index).all()\n",
    "assert (X_test_all_new.index == sib_new.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new siblings\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\[username]\\\\Downloads\\\\\")\n",
    "\n",
    "sib_train = pd.read_csv('Data for Model\\siblings_test_rq2_ts_str_new.csv', index_col = 0, header = None)\n",
    "sib_train = pd.read_csv('Data for Model\\siblings_train_rq2_ts_str_new.csv', index_col = 0, header = None)\n",
    "assert len(set(sib_test[1]).intersection(set(sib_train[1]))) <= 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
