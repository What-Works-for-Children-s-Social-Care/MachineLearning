{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable set-up\n",
    "\n",
    "rq = 'rq2' # Options: 'rq1', 'rq2'\n",
    "cv = 'ss' # Options: 'ts' (time series split, ignore siblings), 'ss' (stratified shuffle, ignore siblings)\n",
    "data_type = 'all' # Options: 'str' (just structured data), 'all' (structured data and list of strings)\n",
    "algorithm_names = ['decision_tree', 'logistic_regression', 'gradient_boosting'] \n",
    "#resampling_name = 'oss' # anything other than 'ada' does 'smote' \n",
    "#select_features_alpha = 0.001 # 0 to keep all features. Should be highest 0.001 as otherwise all dropped\n",
    "rcv_n_iter = 50 # The more iterations, the more the randomised search searches for an optimal solution\n",
    "parameters = 2 # \n",
    "\n",
    "# Don't change\n",
    "file_stub_y_siblings = rq + '_' + cv + '_str' # use 'str' for all \n",
    "file_stub = rq + '_' + cv + '_' + data_type # Creates file stub for saving in the format e.g. rq1_ss_str\n",
    "levers =  str(rcv_n_iter) + '_' + str(parameters)\n",
    "print(file_stub + '_' + levers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File directories\n",
    "local_dir = '/Users/[username]/Documents/Final transfer out data and code to WWC Jan 2020' # insert [username]\n",
    "hard_drive_dir = '/Volumes/diskAshur2/Final transfer out data and code to WWC Jan 2020/Data for model/Use'\n",
    "summary_info = '/Users/[username]/Documents/Summary information'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user-written functions \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import analysis_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "import os\n",
    "import pickle\n",
    "os.chdir(hard_drive_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic results\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file_list = glob.glob(\"{}/Models/topic_modelling_results_{}_*.csv\".format(local_dir, file_stub))\n",
    "\n",
    "file_dict = {}\n",
    "for file_name in file_list:\n",
    "    file = pd.read_csv(file_name)\n",
    "    file_name = file_name.replace(\"{}/Models/topic_modelling_results_\".format(local_dir), \"\")\n",
    "    file_name = file_name.replace(\".csv\", \"\")\n",
    "    file_dict[file_name] = file\n",
    "    \n",
    "print(file_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bring in source and base\n",
    "years_sample_sizes = pd.read_csv(\"{}/Years and Sample Sizes.csv\".format(summary_info))\n",
    "\n",
    "# Identify source and base\n",
    "dict_names = {'ss': 'learning from all cases',\n",
    "             'ts': 'learning just from earlier cases',\n",
    "             'str': 'structured data only',\n",
    "             'all': 'structured and text data'}\n",
    "\n",
    "outcome = years_sample_sizes.loc[(years_sample_sizes['Local authority'] == 'LA2') &\n",
    "                       (years_sample_sizes['Research question'] == rq) & \n",
    "                        (years_sample_sizes['Cross-Validation'] == cv),'Shortened outcome'].values[0]    \n",
    "\n",
    "years = years_sample_sizes.loc[(years_sample_sizes['Local authority'] == 'LA2') &\n",
    "                       (years_sample_sizes['Research question'] == rq) & \n",
    "                        (years_sample_sizes['Cross-Validation'] == cv),'Years'].values[0]\n",
    "\n",
    "sample_sizes = years_sample_sizes.loc[(years_sample_sizes['Local authority'] == 'LA2') &\n",
    "                       (years_sample_sizes['Research question'] == rq) &\n",
    "                       (years_sample_sizes['Cross-Validation'] == cv), 'Sample size'].values[0]\n",
    "\n",
    "txt_source = 'Prediction: {}'.format(outcome)\n",
    "print(txt_source)\n",
    "txt_model_desc = 'Model: {}, {}'.format(dict_names[cv], dict_names[data_type])\n",
    "print(txt_model_desc)\n",
    "txt_base = 'Data: {}, {}, N = {}'.format('Local authority 2', years, sample_sizes)\n",
    "print(txt_base)\n",
    "\n",
    "if cv == 'ts':\n",
    "    cv_for_graph = 'learning just from earlier cases'\n",
    "if cv == 'ss':\n",
    "    cv_for_graph = 'learning from all cases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "\n",
    "\n",
    "for col, topic_modelling_results in file_dict.items():\n",
    "\n",
    "    topics_1 = topic_modelling_results.loc[(topic_modelling_results['tfidf__max_features'] == 30.0) & \n",
    "                                                             (topic_modelling_results['param_lda__max_iter'] == 100),]\n",
    "\n",
    "    topics_2 = topic_modelling_results.loc[(topic_modelling_results['tfidf__max_features'] == 25.0) & \n",
    "                                                             (topic_modelling_results['param_lda__max_iter'] == 100),]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(topics_1['param_lda__n_components'], topics_1['mean_test_score'], '^-', color='#ff7057', label = 'Maximum features = 25')\n",
    "    ax.plot(topics_2['param_lda__n_components'], topics_2['mean_test_score'], 'o-', color='#ff7057', label = 'Maximum features = 30')\n",
    "\n",
    "\n",
    "    ax.tick_params(axis='both', which='both', length=0, colors='#4d4d51')\n",
    "\n",
    "    plt.xlabel('Number of topics', fontname=\"Arial\", color='#4d4d51', fontsize=12)\n",
    "    plt.ylabel('Log likelihood', fontname=\"Arial\", color='#4d4d51', fontsize=12)\n",
    "    ax.set_xticks(np.arange(2,8,2))\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.yaxis.grid(color='#d0dde1')  \n",
    "    title = '\\n'.join(wrap('How well the topic model explains the data (as measured by log likelihood) for increasing numbers of topics', 60))\n",
    "    ax.set_title(title, fontname=\"Arial\", color = '#4d4d51', fontsize=12, loc='left')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.suptitle('LIKELIHOOD OF TOPIC MODEL BY NUMBER OF TOPICS', fontname=\"Arial\", color = '#ff7057', fontsize=12, x=0.5, y=1.05)\n",
    "    legend = plt.legend()\n",
    "    plt.setp(legend.get_texts(), color='#4d4d51')\n",
    "\n",
    "    plt.figtext(0, -0.05, txt_source, wrap=True, fontname=\"Arial\", color='#4d4d51', fontsize=12)\n",
    "    plt.figtext(0, -0.1, txt_model_desc, wrap=True, fontname=\"Arial\", color='#4d4d51', fontsize=12)\n",
    "    plt.figtext(0, -0.15, txt_base, wrap=True, fontname=\"Arial\", color='#4d4d51', fontsize=12)\n",
    "\n",
    "    plt.savefig('{}/Graphs/Elbow Plots {} ({}).png'.format(local_dir, file_stub, col), transparent=False, dpi=80, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the dataframes\n",
    "df_list = []\n",
    "for col, topic_modelling_results in file_dict.items():\n",
    "    df = file_dict[col][['mean_test_score', 'std_test_score',\n",
    "           'param_lda__max_iter', 'param_lda__n_components',\n",
    "           'tfidf__max_features']]\n",
    "    df['mean_test_score'] = round(df['mean_test_score'] ,2)\n",
    "    df['std_test_score'] = round(df['std_test_score'] ,2)\n",
    "    df['Document'] = col\n",
    "    df_list.append(df)\n",
    "\n",
    "# Create dataset to save\n",
    "results = pd.concat(df_list, axis=0)\n",
    "results.rename(columns = {'mean_test_score': 'Mean test score', 'std_test_score': 'Standard deviation test score', \n",
    "                          'param_lda__max_iter': 'Maximum iterations', 'param_lda__n_components': 'Number of components',\n",
    "                          'tfidf__max_features': 'Maximum number of features'}, inplace = True)\n",
    "\n",
    "results = results[['Document',\n",
    "'Maximum iterations', 'Number of components',\n",
    "'Maximum number of features', 'Mean test score', \n",
    "'Standard deviation test score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Document'].replace({'{}_Child Social Work Assessment to Initial Child Protection Conference_text_prev'.format(file_stub): 'Report to previous Initial Child Protection Conferences',\n",
    "       '{}_Contact and Referral Form_text'.format(file_stub): 'Contact and Referral Record',\n",
    "       '{}_Child Social Work Assessment_text_prev'.format(file_stub): 'Assessment',\n",
    "       '{}_Child Social Work Assessment for Review Child Protection Conference_text_prev'.format(file_stub): 'Report to previous Review Child Protection Conferences',\n",
    "       '{}_Child Social Work Assessment to Initial Child Protection Conference_text'.format(file_stub): 'Report to Review Child Protection Conference'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"{}/Models/Log Likelihood_{}.csv\".format(local_dir, file_stub), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
