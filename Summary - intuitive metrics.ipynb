{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creates summary of intuitive metrics\n",
    "- Creates final metrics for visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in list of model performance metrics\n",
    "import glob\n",
    "import pandas as pd\n",
    "file_list = glob.glob(\"*/*.csv\")\n",
    "file_list_excel = glob.glob(\"*/*.xlsx\")\n",
    "file_list = [f for f in file_list if 'Intuitive' in f]\n",
    "file_list = [f for f in file_list if 'Output' not in f]\n",
    "file_list_excel = [f for f in file_list_excel if 'Intuitive' in f]\n",
    "file_list = file_list + file_list_excel\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Create single dataframe of all intuitive metrics\n",
    "file_dict = {}\n",
    "for file_name in file_list:\n",
    "    if 'LA1' in file_name:\n",
    "        file = pd.read_excel(file_name,header = None)\n",
    "    else:\n",
    "        file = pd.read_csv(file_name, header = None)\n",
    "    file_name = file_name.replace(\".xlsx\", \"\")  \n",
    "    file_name = file_name.replace(\"Intuitive metrics \", \"\")\n",
    "    LA, model_id = file_name.split('/')\n",
    "    file['LA'] = LA\n",
    "    file['model_id'] = model_id\n",
    "    file_dict[file_name] = file\n",
    "\n",
    "print(file_dict.keys())\n",
    "\n",
    "for key in file_dict.keys():\n",
    "    file_dict[key].columns = ['Metric', 'N', 'LA', 'model_id']\n",
    "    \n",
    "results = pd.concat(file_dict.values(), axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean N\n",
    "results_mean = pd.DataFrame(results.groupby('Metric')['N'].mean())\n",
    "results_mean = results_mean.round(0)\n",
    "results_mean.to_csv('Output/Intuitive metrics summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of metrics by LA, RQ\n",
    "results['rq'] = results['model_id'].str.split('_', expand = True)[0]\n",
    "results_mean_LA = pd.DataFrame(results.groupby(['LA', 'rq', 'Metric'])['N'].mean())\n",
    "results_mean_LA = results_mean_LA.round(0)\n",
    "results_mean_LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean_LA.to_csv('Output/Summary intuitive metrics rq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
